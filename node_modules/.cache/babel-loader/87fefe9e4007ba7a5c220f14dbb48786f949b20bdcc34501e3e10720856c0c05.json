{"ast":null,"code":"var _jsxFileName = \"/Users/maryamcheema/Documents/VideoAccessibility/frontend/src/components/ChatGPT.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport { useSpeechSynthesis } from 'react-speech-kit';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst ChatGPT = () => {\n  _s();\n  const [videoDescriptions, setVideoDescriptions] = useState([\"Description for video 1\", \"Description for video 2\", \"Description for video 3\"\n  // Add more video descriptions as needed\n  ]);\n\n  const [currentDescriptionIndex, setCurrentDescriptionIndex] = useState(0);\n  const {\n    speak,\n    cancel,\n    speaking\n  } = useSpeechSynthesis();\n  useEffect(() => {\n    // Function to handle video progress and change descriptions\n    const handleVideoProgress = () => {\n      const video = document.getElementById('video');\n      const currentTime = video.currentTime;\n      // Logic to change descriptions based on video progress\n      if (currentTime >= 5 && currentDescriptionIndex === 0) {\n        setCurrentDescriptionIndex(1);\n        // Pause the video\n        video.pause();\n        // Speak the description\n        speak({\n          text: videoDescriptions[currentDescriptionIndex]\n        });\n      } else if (currentTime >= 10 && currentDescriptionIndex === 1) {\n        setCurrentDescriptionIndex(2);\n        // Pause the video\n        video.pause();\n        // Speak the description\n        speak({\n          text: videoDescriptions[currentDescriptionIndex]\n        });\n      }\n      // Add more conditions for other time intervals and descriptions as needed\n    };\n\n    // Add event listener for video progress\n    document.getElementById('video').addEventListener('timeupdate', handleVideoProgress);\n\n    // Clean up event listener on component unmount\n    return () => {\n      document.getElementById('video').removeEventListener('timeupdate', handleVideoProgress);\n      // Cancel speech synthesis when component unmounts\n      cancel();\n    };\n  }, [currentDescriptionIndex, videoDescriptions, speak, cancel]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      id: \"video\",\n      controls: true,\n      width: \"640\",\n      height: \"360\",\n      children: [/*#__PURE__*/_jsxDEV(\"source\", {\n        src: \"your_video_url.mp4\",\n        type: \"video/mp4\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 51,\n        columnNumber: 9\n      }, this), \"Your browser does not support the video tag.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 50,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"Video Description\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 56,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: videoDescriptions[currentDescriptionIndex]\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 57,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 55,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: speaking && /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Speaking...\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 61,\n        columnNumber: 22\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 60,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 49,\n    columnNumber: 5\n  }, this);\n};\n_s(ChatGPT, \"w5968nZ2gWdbhsotkUxCswZRIF0=\", false, function () {\n  return [useSpeechSynthesis];\n});\n_c = ChatGPT;\nexport default ChatGPT;\n\n// import React, { useState, useEffect } from 'react';\n// import { TextToSpeech } from \"./\";\n\n// const ChatGPT = (props) => {\n//   const video = require('./' + props.path);\n//   const [videoDescriptions, setVideoDescriptions] = useState([\n//     { timestamp: 0, description: \"Description for start of video\" },\n//     { timestamp: 5, description: \"Description at 5 seconds\" },\n//     { timestamp: 10, description: \"Description at 10 seconds\" },\n//     // Add more descriptions with timestamps as needed\n//   ]);\n\n//   const [currentDescriptionIndex, setCurrentDescriptionIndex] = useState(0);\n//   const [isPlaying, setIsPlaying] = useState(false);\n//   const [isSpeechPlaying, setIsSpeechPlaying] = useState(false);\n\n//   useEffect(() => {\n//     const video = document.getElementById('video');\n\n//     const handleTimeUpdate = () => {\n//       const currentTime = Math.floor(video.currentTime);\n//       const index = videoDescriptions.findIndex(description => description.timestamp === currentTime);\n\n//       if (index !== -1 && index !== currentDescriptionIndex) {\n//         setCurrentDescriptionIndex(index);\n//         video.pause();\n//       }\n//     };\n\n//     video.addEventListener('timeupdate', handleTimeUpdate);\n\n//     return () => {\n//       video.removeEventListener('timeupdate', handleTimeUpdate);\n//     };\n//   }, [currentDescriptionIndex, videoDescriptions]);\n\n//   return (\n//     <div>\n//       <video id=\"video\" controls width=\"640\" height=\"360\">\n//         <source src={video} type=\"video/mp4\" />\n//         Your browser does not support the video tag.\n//       </video>\n\n//       <div>\n//         <h2>Video Description</h2>\n//         <p>{videoDescriptions[currentDescriptionIndex].description}</p>\n//         <TextToSpeech\n//             text={videoDescriptions[currentDescriptionIndex].description}\n//             isPlayed={isSpeechPlaying}\n//             onStart={() => setIsSpeechPlaying(true)}\n//             onEnd={() => setIsSpeechPlaying(false)}\n//           />\n//       </div>\n//     </div>\n//   );\n// };\n\n// export default ChatGPT;\nvar _c;\n$RefreshReg$(_c, \"ChatGPT\");","map":{"version":3,"names":["React","useState","useEffect","useSpeechSynthesis","jsxDEV","_jsxDEV","ChatGPT","_s","videoDescriptions","setVideoDescriptions","currentDescriptionIndex","setCurrentDescriptionIndex","speak","cancel","speaking","handleVideoProgress","video","document","getElementById","currentTime","pause","text","addEventListener","removeEventListener","children","id","controls","width","height","src","type","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/maryamcheema/Documents/VideoAccessibility/frontend/src/components/ChatGPT.jsx"],"sourcesContent":["import React, { useState, useEffect } from 'react';\nimport { useSpeechSynthesis } from 'react-speech-kit';\n\nconst ChatGPT = () => {\n  const [videoDescriptions, setVideoDescriptions] = useState([\n    \"Description for video 1\",\n    \"Description for video 2\",\n    \"Description for video 3\",\n    // Add more video descriptions as needed\n  ]);\n\n  const [currentDescriptionIndex, setCurrentDescriptionIndex] = useState(0);\n  const { speak, cancel, speaking } = useSpeechSynthesis();\n\n  useEffect(() => {\n    // Function to handle video progress and change descriptions\n    const handleVideoProgress = () => {\n      const video = document.getElementById('video');\n      const currentTime = video.currentTime;\n      // Logic to change descriptions based on video progress\n      if (currentTime >= 5 && currentDescriptionIndex === 0) {\n        setCurrentDescriptionIndex(1);\n        // Pause the video\n        video.pause();\n        // Speak the description\n        speak({ text: videoDescriptions[currentDescriptionIndex] });\n      } else if (currentTime >= 10 && currentDescriptionIndex === 1) {\n        setCurrentDescriptionIndex(2);\n        // Pause the video\n        video.pause();\n        // Speak the description\n        speak({ text: videoDescriptions[currentDescriptionIndex] });\n      }\n      // Add more conditions for other time intervals and descriptions as needed\n    };\n\n    // Add event listener for video progress\n    document.getElementById('video').addEventListener('timeupdate', handleVideoProgress);\n\n    // Clean up event listener on component unmount\n    return () => {\n      document.getElementById('video').removeEventListener('timeupdate', handleVideoProgress);\n      // Cancel speech synthesis when component unmounts\n      cancel();\n    };\n  }, [currentDescriptionIndex, videoDescriptions, speak, cancel]);\n\n  return (\n    <div>\n      <video id=\"video\" controls width=\"640\" height=\"360\">\n        <source src=\"your_video_url.mp4\" type=\"video/mp4\" />\n        Your browser does not support the video tag.\n      </video>\n\n      <div>\n        <h2>Video Description</h2>\n        <p>{videoDescriptions[currentDescriptionIndex]}</p>\n      </div>\n\n      <div>\n        {speaking && <p>Speaking...</p>}\n      </div>\n    </div>\n  );\n};\n\nexport default ChatGPT;\n\n\n\n\n// import React, { useState, useEffect } from 'react';\n// import { TextToSpeech } from \"./\";\n\n// const ChatGPT = (props) => {\n//   const video = require('./' + props.path);\n//   const [videoDescriptions, setVideoDescriptions] = useState([\n//     { timestamp: 0, description: \"Description for start of video\" },\n//     { timestamp: 5, description: \"Description at 5 seconds\" },\n//     { timestamp: 10, description: \"Description at 10 seconds\" },\n//     // Add more descriptions with timestamps as needed\n//   ]);\n\n//   const [currentDescriptionIndex, setCurrentDescriptionIndex] = useState(0);\n//   const [isPlaying, setIsPlaying] = useState(false);\n//   const [isSpeechPlaying, setIsSpeechPlaying] = useState(false);\n\n//   useEffect(() => {\n//     const video = document.getElementById('video');\n\n//     const handleTimeUpdate = () => {\n//       const currentTime = Math.floor(video.currentTime);\n//       const index = videoDescriptions.findIndex(description => description.timestamp === currentTime);\n\n//       if (index !== -1 && index !== currentDescriptionIndex) {\n//         setCurrentDescriptionIndex(index);\n//         video.pause();\n//       }\n//     };\n\n//     video.addEventListener('timeupdate', handleTimeUpdate);\n\n//     return () => {\n//       video.removeEventListener('timeupdate', handleTimeUpdate);\n//     };\n//   }, [currentDescriptionIndex, videoDescriptions]);\n\n\n//   return (\n//     <div>\n//       <video id=\"video\" controls width=\"640\" height=\"360\">\n//         <source src={video} type=\"video/mp4\" />\n//         Your browser does not support the video tag.\n//       </video>\n\n//       <div>\n//         <h2>Video Description</h2>\n//         <p>{videoDescriptions[currentDescriptionIndex].description}</p>\n//         <TextToSpeech\n//             text={videoDescriptions[currentDescriptionIndex].description}\n//             isPlayed={isSpeechPlaying}\n//             onStart={() => setIsSpeechPlaying(true)}\n//             onEnd={() => setIsSpeechPlaying(false)}\n//           />\n//       </div>\n//     </div>\n//   );\n// };\n\n// export default ChatGPT;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,SAASC,kBAAkB,QAAQ,kBAAkB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEtD,MAAMC,OAAO,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACpB,MAAM,CAACC,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGR,QAAQ,CAAC,CACzD,yBAAyB,EACzB,yBAAyB,EACzB;EACA;EAAA,CACD,CAAC;;EAEF,MAAM,CAACS,uBAAuB,EAAEC,0BAA0B,CAAC,GAAGV,QAAQ,CAAC,CAAC,CAAC;EACzE,MAAM;IAAEW,KAAK;IAAEC,MAAM;IAAEC;EAAS,CAAC,GAAGX,kBAAkB,CAAC,CAAC;EAExDD,SAAS,CAAC,MAAM;IACd;IACA,MAAMa,mBAAmB,GAAGA,CAAA,KAAM;MAChC,MAAMC,KAAK,GAAGC,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC;MAC9C,MAAMC,WAAW,GAAGH,KAAK,CAACG,WAAW;MACrC;MACA,IAAIA,WAAW,IAAI,CAAC,IAAIT,uBAAuB,KAAK,CAAC,EAAE;QACrDC,0BAA0B,CAAC,CAAC,CAAC;QAC7B;QACAK,KAAK,CAACI,KAAK,CAAC,CAAC;QACb;QACAR,KAAK,CAAC;UAAES,IAAI,EAAEb,iBAAiB,CAACE,uBAAuB;QAAE,CAAC,CAAC;MAC7D,CAAC,MAAM,IAAIS,WAAW,IAAI,EAAE,IAAIT,uBAAuB,KAAK,CAAC,EAAE;QAC7DC,0BAA0B,CAAC,CAAC,CAAC;QAC7B;QACAK,KAAK,CAACI,KAAK,CAAC,CAAC;QACb;QACAR,KAAK,CAAC;UAAES,IAAI,EAAEb,iBAAiB,CAACE,uBAAuB;QAAE,CAAC,CAAC;MAC7D;MACA;IACF,CAAC;;IAED;IACAO,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC,CAACI,gBAAgB,CAAC,YAAY,EAAEP,mBAAmB,CAAC;;IAEpF;IACA,OAAO,MAAM;MACXE,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC,CAACK,mBAAmB,CAAC,YAAY,EAAER,mBAAmB,CAAC;MACvF;MACAF,MAAM,CAAC,CAAC;IACV,CAAC;EACH,CAAC,EAAE,CAACH,uBAAuB,EAAEF,iBAAiB,EAAEI,KAAK,EAAEC,MAAM,CAAC,CAAC;EAE/D,oBACER,OAAA;IAAAmB,QAAA,gBACEnB,OAAA;MAAOoB,EAAE,EAAC,OAAO;MAACC,QAAQ;MAACC,KAAK,EAAC,KAAK;MAACC,MAAM,EAAC,KAAK;MAAAJ,QAAA,gBACjDnB,OAAA;QAAQwB,GAAG,EAAC,oBAAoB;QAACC,IAAI,EAAC;MAAW;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,gDAEtD;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAO,CAAC,eAER7B,OAAA;MAAAmB,QAAA,gBACEnB,OAAA;QAAAmB,QAAA,EAAI;MAAiB;QAAAO,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAC1B7B,OAAA;QAAAmB,QAAA,EAAIhB,iBAAiB,CAACE,uBAAuB;MAAC;QAAAqB,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAChD,CAAC,eAEN7B,OAAA;MAAAmB,QAAA,EACGV,QAAQ,iBAAIT,OAAA;QAAAmB,QAAA,EAAG;MAAW;QAAAO,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC5B,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAAC3B,EAAA,CA7DID,OAAO;EAAA,QASyBH,kBAAkB;AAAA;AAAAgC,EAAA,GATlD7B,OAAO;AA+Db,eAAeA,OAAO;;AAKtB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA,IAAA6B,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}