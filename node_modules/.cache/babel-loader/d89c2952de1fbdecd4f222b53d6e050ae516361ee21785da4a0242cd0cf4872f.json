{"ast":null,"code":"var _jsxFileName = \"/Users/maryamcheema/Documents/VideoAccessibility/frontend/src/components/ChatGPT.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport { useSpeechSynthesis } from 'react-speech-kit';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst ChatGPT = props => {\n  _s();\n  const video = require('./' + props.path);\n  const [videoDescriptions, setVideoDescriptions] = useState([\"Description for video 1\", \"Description for video 2\", \"Description for video 3\"\n  // Add more video descriptions as needed\n  ]);\n\n  const [currentDescriptionIndex, setCurrentDescriptionIndex] = useState(0);\n  const {\n    speak,\n    cancel,\n    speaking\n  } = useSpeechSynthesis();\n  useEffect(() => {\n    // Function to handle video progress and change descriptions\n    const handleVideoProgress = () => {\n      const video = document.getElementById('video');\n      const currentTime = video.currentTime;\n      // Logic to change descriptions based on video progress\n      if (currentTime >= 5 && currentDescriptionIndex === 0) {\n        setCurrentDescriptionIndex(1);\n        // Pause the video\n        video.pause();\n        // Speak the description\n        speak({\n          text: videoDescriptions[currentDescriptionIndex]\n        });\n      } else if (currentTime >= 10 && currentDescriptionIndex === 1) {\n        setCurrentDescriptionIndex(2);\n        // Pause the video\n        video.pause();\n        // Speak the description\n        speak({\n          text: videoDescriptions[currentDescriptionIndex]\n        });\n      }\n      // Add more conditions for other time intervals and descriptions as needed\n    };\n\n    // Add event listener for video progress\n    document.getElementById('video').addEventListener('timeupdate', handleVideoProgress);\n\n    // Clean up event listener on component unmount\n    return () => {\n      document.getElementById('video').removeEventListener('timeupdate', handleVideoProgress);\n      // Cancel speech synthesis when component unmounts\n      cancel();\n    };\n  }, [currentDescriptionIndex, videoDescriptions, speak, cancel]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      id: \"video\",\n      controls: true,\n      width: \"640\",\n      height: \"360\",\n      children: [/*#__PURE__*/_jsxDEV(\"source\", {\n        src: video,\n        type: \"video/mp4\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 52,\n        columnNumber: 9\n      }, this), \"Your browser does not support the video tag.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 51,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"Video Description\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 57,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: videoDescriptions[currentDescriptionIndex]\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 58,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 56,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: speaking && /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Speaking...\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 62,\n        columnNumber: 22\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 61,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 50,\n    columnNumber: 5\n  }, this);\n};\n_s(ChatGPT, \"w5968nZ2gWdbhsotkUxCswZRIF0=\", false, function () {\n  return [useSpeechSynthesis];\n});\n_c = ChatGPT;\nexport default ChatGPT;\n\n// import React, { useState, useEffect } from 'react';\n// import { TextToSpeech } from \"./\";\n\n// const ChatGPT = (props) => {\n//   const video = require('./' + props.path);\n//   const [videoDescriptions, setVideoDescriptions] = useState([\n//     { timestamp: 0, description: \"Description for start of video\" },\n//     { timestamp: 5, description: \"Description at 5 seconds\" },\n//     { timestamp: 10, description: \"Description at 10 seconds\" },\n//     // Add more descriptions with timestamps as needed\n//   ]);\n\n//   const [currentDescriptionIndex, setCurrentDescriptionIndex] = useState(0);\n//   const [isPlaying, setIsPlaying] = useState(false);\n//   const [isSpeechPlaying, setIsSpeechPlaying] = useState(false);\n\n//   useEffect(() => {\n//     const video = document.getElementById('video');\n\n//     const handleTimeUpdate = () => {\n//       const currentTime = Math.floor(video.currentTime);\n//       const index = videoDescriptions.findIndex(description => description.timestamp === currentTime);\n\n//       if (index !== -1 && index !== currentDescriptionIndex) {\n//         setCurrentDescriptionIndex(index);\n//         video.pause();\n//       }\n//     };\n\n//     video.addEventListener('timeupdate', handleTimeUpdate);\n\n//     return () => {\n//       video.removeEventListener('timeupdate', handleTimeUpdate);\n//     };\n//   }, [currentDescriptionIndex, videoDescriptions]);\n\n//   return (\n//     <div>\n//       <video id=\"video\" controls width=\"640\" height=\"360\">\n//         <source src={video} type=\"video/mp4\" />\n//         Your browser does not support the video tag.\n//       </video>\n\n//       <div>\n//         <h2>Video Description</h2>\n//         <p>{videoDescriptions[currentDescriptionIndex].description}</p>\n//         <TextToSpeech\n//             text={videoDescriptions[currentDescriptionIndex].description}\n//             isPlayed={isSpeechPlaying}\n//             onStart={() => setIsSpeechPlaying(true)}\n//             onEnd={() => setIsSpeechPlaying(false)}\n//           />\n//       </div>\n//     </div>\n//   );\n// };\n\n// export default ChatGPT;\nvar _c;\n$RefreshReg$(_c, \"ChatGPT\");","map":{"version":3,"names":["React","useState","useEffect","useSpeechSynthesis","jsxDEV","_jsxDEV","ChatGPT","props","_s","video","require","path","videoDescriptions","setVideoDescriptions","currentDescriptionIndex","setCurrentDescriptionIndex","speak","cancel","speaking","handleVideoProgress","document","getElementById","currentTime","pause","text","addEventListener","removeEventListener","children","id","controls","width","height","src","type","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/maryamcheema/Documents/VideoAccessibility/frontend/src/components/ChatGPT.jsx"],"sourcesContent":["import React, { useState, useEffect } from 'react';\nimport { useSpeechSynthesis } from 'react-speech-kit';\n\nconst ChatGPT = (props) => {\nconst video = require('./' + props.path);\n  const [videoDescriptions, setVideoDescriptions] = useState([\n    \"Description for video 1\",\n    \"Description for video 2\",\n    \"Description for video 3\",\n    // Add more video descriptions as needed\n  ]);\n\n  const [currentDescriptionIndex, setCurrentDescriptionIndex] = useState(0);\n  const { speak, cancel, speaking } = useSpeechSynthesis();\n\n  useEffect(() => {\n    // Function to handle video progress and change descriptions\n    const handleVideoProgress = () => {\n      const video = document.getElementById('video');\n      const currentTime = video.currentTime;\n      // Logic to change descriptions based on video progress\n      if (currentTime >= 5 && currentDescriptionIndex === 0) {\n        setCurrentDescriptionIndex(1);\n        // Pause the video\n        video.pause();\n        // Speak the description\n        speak({ text: videoDescriptions[currentDescriptionIndex] });\n      } else if (currentTime >= 10 && currentDescriptionIndex === 1) {\n        setCurrentDescriptionIndex(2);\n        // Pause the video\n        video.pause();\n        // Speak the description\n        speak({ text: videoDescriptions[currentDescriptionIndex] });\n      }\n      // Add more conditions for other time intervals and descriptions as needed\n    };\n\n    // Add event listener for video progress\n    document.getElementById('video').addEventListener('timeupdate', handleVideoProgress);\n\n    // Clean up event listener on component unmount\n    return () => {\n      document.getElementById('video').removeEventListener('timeupdate', handleVideoProgress);\n      // Cancel speech synthesis when component unmounts\n      cancel();\n    };\n  }, [currentDescriptionIndex, videoDescriptions, speak, cancel]);\n\n  return (\n    <div>\n      <video id=\"video\" controls width=\"640\" height=\"360\">\n        <source src={video} type=\"video/mp4\" />\n        Your browser does not support the video tag.\n      </video>\n\n      <div>\n        <h2>Video Description</h2>\n        <p>{videoDescriptions[currentDescriptionIndex]}</p>\n      </div>\n\n      <div>\n        {speaking && <p>Speaking...</p>}\n      </div>\n    </div>\n  );\n};\n\nexport default ChatGPT;\n\n\n\n\n// import React, { useState, useEffect } from 'react';\n// import { TextToSpeech } from \"./\";\n\n// const ChatGPT = (props) => {\n//   const video = require('./' + props.path);\n//   const [videoDescriptions, setVideoDescriptions] = useState([\n//     { timestamp: 0, description: \"Description for start of video\" },\n//     { timestamp: 5, description: \"Description at 5 seconds\" },\n//     { timestamp: 10, description: \"Description at 10 seconds\" },\n//     // Add more descriptions with timestamps as needed\n//   ]);\n\n//   const [currentDescriptionIndex, setCurrentDescriptionIndex] = useState(0);\n//   const [isPlaying, setIsPlaying] = useState(false);\n//   const [isSpeechPlaying, setIsSpeechPlaying] = useState(false);\n\n//   useEffect(() => {\n//     const video = document.getElementById('video');\n\n//     const handleTimeUpdate = () => {\n//       const currentTime = Math.floor(video.currentTime);\n//       const index = videoDescriptions.findIndex(description => description.timestamp === currentTime);\n\n//       if (index !== -1 && index !== currentDescriptionIndex) {\n//         setCurrentDescriptionIndex(index);\n//         video.pause();\n//       }\n//     };\n\n//     video.addEventListener('timeupdate', handleTimeUpdate);\n\n//     return () => {\n//       video.removeEventListener('timeupdate', handleTimeUpdate);\n//     };\n//   }, [currentDescriptionIndex, videoDescriptions]);\n\n\n//   return (\n//     <div>\n//       <video id=\"video\" controls width=\"640\" height=\"360\">\n//         <source src={video} type=\"video/mp4\" />\n//         Your browser does not support the video tag.\n//       </video>\n\n//       <div>\n//         <h2>Video Description</h2>\n//         <p>{videoDescriptions[currentDescriptionIndex].description}</p>\n//         <TextToSpeech\n//             text={videoDescriptions[currentDescriptionIndex].description}\n//             isPlayed={isSpeechPlaying}\n//             onStart={() => setIsSpeechPlaying(true)}\n//             onEnd={() => setIsSpeechPlaying(false)}\n//           />\n//       </div>\n//     </div>\n//   );\n// };\n\n// export default ChatGPT;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,SAASC,kBAAkB,QAAQ,kBAAkB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEtD,MAAMC,OAAO,GAAIC,KAAK,IAAK;EAAAC,EAAA;EAC3B,MAAMC,KAAK,GAAGC,OAAO,CAAC,IAAI,GAAGH,KAAK,CAACI,IAAI,CAAC;EACtC,MAAM,CAACC,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGZ,QAAQ,CAAC,CACzD,yBAAyB,EACzB,yBAAyB,EACzB;EACA;EAAA,CACD,CAAC;;EAEF,MAAM,CAACa,uBAAuB,EAAEC,0BAA0B,CAAC,GAAGd,QAAQ,CAAC,CAAC,CAAC;EACzE,MAAM;IAAEe,KAAK;IAAEC,MAAM;IAAEC;EAAS,CAAC,GAAGf,kBAAkB,CAAC,CAAC;EAExDD,SAAS,CAAC,MAAM;IACd;IACA,MAAMiB,mBAAmB,GAAGA,CAAA,KAAM;MAChC,MAAMV,KAAK,GAAGW,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC;MAC9C,MAAMC,WAAW,GAAGb,KAAK,CAACa,WAAW;MACrC;MACA,IAAIA,WAAW,IAAI,CAAC,IAAIR,uBAAuB,KAAK,CAAC,EAAE;QACrDC,0BAA0B,CAAC,CAAC,CAAC;QAC7B;QACAN,KAAK,CAACc,KAAK,CAAC,CAAC;QACb;QACAP,KAAK,CAAC;UAAEQ,IAAI,EAAEZ,iBAAiB,CAACE,uBAAuB;QAAE,CAAC,CAAC;MAC7D,CAAC,MAAM,IAAIQ,WAAW,IAAI,EAAE,IAAIR,uBAAuB,KAAK,CAAC,EAAE;QAC7DC,0BAA0B,CAAC,CAAC,CAAC;QAC7B;QACAN,KAAK,CAACc,KAAK,CAAC,CAAC;QACb;QACAP,KAAK,CAAC;UAAEQ,IAAI,EAAEZ,iBAAiB,CAACE,uBAAuB;QAAE,CAAC,CAAC;MAC7D;MACA;IACF,CAAC;;IAED;IACAM,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC,CAACI,gBAAgB,CAAC,YAAY,EAAEN,mBAAmB,CAAC;;IAEpF;IACA,OAAO,MAAM;MACXC,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC,CAACK,mBAAmB,CAAC,YAAY,EAAEP,mBAAmB,CAAC;MACvF;MACAF,MAAM,CAAC,CAAC;IACV,CAAC;EACH,CAAC,EAAE,CAACH,uBAAuB,EAAEF,iBAAiB,EAAEI,KAAK,EAAEC,MAAM,CAAC,CAAC;EAE/D,oBACEZ,OAAA;IAAAsB,QAAA,gBACEtB,OAAA;MAAOuB,EAAE,EAAC,OAAO;MAACC,QAAQ;MAACC,KAAK,EAAC,KAAK;MAACC,MAAM,EAAC,KAAK;MAAAJ,QAAA,gBACjDtB,OAAA;QAAQ2B,GAAG,EAAEvB,KAAM;QAACwB,IAAI,EAAC;MAAW;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,gDAEzC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAO,CAAC,eAERhC,OAAA;MAAAsB,QAAA,gBACEtB,OAAA;QAAAsB,QAAA,EAAI;MAAiB;QAAAO,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAC1BhC,OAAA;QAAAsB,QAAA,EAAIf,iBAAiB,CAACE,uBAAuB;MAAC;QAAAoB,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAChD,CAAC,eAENhC,OAAA;MAAAsB,QAAA,EACGT,QAAQ,iBAAIb,OAAA;QAAAsB,QAAA,EAAG;MAAW;QAAAO,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC5B,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAAC7B,EAAA,CA9DIF,OAAO;EAAA,QAUyBH,kBAAkB;AAAA;AAAAmC,EAAA,GAVlDhC,OAAO;AAgEb,eAAeA,OAAO;;AAKtB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA,IAAAgC,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}