{"ast":null,"code":"// // import { useState, useEffect } from 'react';\n\n// // function useSpeechRecognition() {\n// //   const [transcript, setTranscript] = useState('');\n// //   const [listening, setListening] = useState(false);\n\n// //   const recognition = new window.SpeechRecognition();\n// //   recognition.continuous = true;\n// //   recognition.lang = 'en-US';\n\n// //   useEffect(() => {\n// //     recognition.onstart = () => {\n// //       console.log('Speech recognition started');\n// //       setListening(true);\n// //     };\n\n// //     recognition.onresult = (event) => {\n// //       const currentTranscript = event.results[event.results.length - 1][0].transcript;\n// //       setTranscript(currentTranscript);\n// //     };\n\n// //     recognition.onend = () => {\n// //       console.log('Speech recognition ended');\n// //       setListening(false);\n// //     };\n\n// //     recognition.onerror = (event) => {\n// //       console.error('Speech recognition error occurred:', event.error);\n// //       setListening(false);\n// //     };\n\n// //     return () => {\n// //       recognition.stop();\n// //     };\n// //   }, []); // Empty dependency array ensures that this effect runs once after the initial render\n\n// //   const startListening = () => {\n// //     recognition.start();\n// //   };\n\n// //   const stopListening = () => {\n// //     recognition.stop();\n// //   };\n\n// //   return {\n// //     listening,\n// //     transcript,\n// //     startListening,\n// //     stopListening,\n// //   };\n// // }\n\n// // export default useSpeechRecognition;\n\n// import React, { useEffect, useState } from \"react\";\n\n// let recognition: any = null;\n// if (\"webkitSpeechRecongition\" in window) {\n//   recognition = new webkitSpeechRecognition();\n//   recognition.continuous = true;\n//   recognition.lang = \"en-US\";\n// }\n\n// const useSpeechRecognition = () => {\n//   const [text, setText] = useState(\"\");\n//   const [isListening, setIsListening] = useState(false);\n\n//   useEffect(() => {\n//     if (!recognition) return;\n\n//     recognition.onresult = (event) => {\n//       console.log(\"on result event: \", event);\n//       recognition.stop();\n//       setIsListening(false);\n//     };\n//   }, []);\n\n//   const startListening = () => {\n//     setText(\"\");\n//     setIsListening(true);\n//     recognition.start();\n//   }\n\n//   const stopListening = () => {\n//     setIsListening(false);\n//     recognition.stop();\n//   }\n\n//   return {\n//     text,\n//     isListening,\n//     startListening,\n//     stopListening,\n//     hasRecognition: !!recognition, \n//   }\n// };\n\n// export default useSpeechRecognition;","map":{"version":3,"names":[],"sources":["/Users/maryamcheema/Documents/VideoAccessibility/frontend/src/hooks/useSpeechRecognition.jsx"],"sourcesContent":["// // import { useState, useEffect } from 'react';\n\n// // function useSpeechRecognition() {\n// //   const [transcript, setTranscript] = useState('');\n// //   const [listening, setListening] = useState(false);\n\n// //   const recognition = new window.SpeechRecognition();\n// //   recognition.continuous = true;\n// //   recognition.lang = 'en-US';\n\n// //   useEffect(() => {\n// //     recognition.onstart = () => {\n// //       console.log('Speech recognition started');\n// //       setListening(true);\n// //     };\n\n// //     recognition.onresult = (event) => {\n// //       const currentTranscript = event.results[event.results.length - 1][0].transcript;\n// //       setTranscript(currentTranscript);\n// //     };\n\n// //     recognition.onend = () => {\n// //       console.log('Speech recognition ended');\n// //       setListening(false);\n// //     };\n\n// //     recognition.onerror = (event) => {\n// //       console.error('Speech recognition error occurred:', event.error);\n// //       setListening(false);\n// //     };\n\n// //     return () => {\n// //       recognition.stop();\n// //     };\n// //   }, []); // Empty dependency array ensures that this effect runs once after the initial render\n\n// //   const startListening = () => {\n// //     recognition.start();\n// //   };\n\n// //   const stopListening = () => {\n// //     recognition.stop();\n// //   };\n\n// //   return {\n// //     listening,\n// //     transcript,\n// //     startListening,\n// //     stopListening,\n// //   };\n// // }\n\n// // export default useSpeechRecognition;\n\n\n\n// import React, { useEffect, useState } from \"react\";\n\n// let recognition: any = null;\n// if (\"webkitSpeechRecongition\" in window) {\n//   recognition = new webkitSpeechRecognition();\n//   recognition.continuous = true;\n//   recognition.lang = \"en-US\";\n// }\n\n// const useSpeechRecognition = () => {\n//   const [text, setText] = useState(\"\");\n//   const [isListening, setIsListening] = useState(false);\n\n//   useEffect(() => {\n//     if (!recognition) return;\n\n//     recognition.onresult = (event) => {\n//       console.log(\"on result event: \", event);\n//       recognition.stop();\n//       setIsListening(false);\n//     };\n//   }, []);\n\n//   const startListening = () => {\n//     setText(\"\");\n//     setIsListening(true);\n//     recognition.start();\n//   }\n\n//   const stopListening = () => {\n//     setIsListening(false);\n//     recognition.stop();\n//   }\n\n//   return {\n//     text,\n//     isListening,\n//     startListening,\n//     stopListening,\n//     hasRecognition: !!recognition, \n//   }\n// };\n\n// export default useSpeechRecognition;\n"],"mappings":"AAAA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAIA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA"},"metadata":{},"sourceType":"module","externalDependencies":[]}