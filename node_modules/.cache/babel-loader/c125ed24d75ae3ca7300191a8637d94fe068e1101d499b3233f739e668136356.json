{"ast":null,"code":"var _s = $RefreshSig$();\nimport React, { useEffect, useState } from \"react\";\nlet recognition = null;\nif (\"webkitSpeechRecongition\" in window) {\n  recognition = new window.SpeechRecognition();\n  recognition.continuous = true;\n  recognition.lang = \"en-US\";\n}\nconst useSpeechRecognition = () => {\n  _s();\n  const [text, setText] = useState(\"\");\n  const [isListening, setIsListening] = useState(false);\n  useEffect(() => {\n    if (!recognition) return;\n    recognition.onresult = event => {\n      console.log(\"on result event: \", event);\n      recognition.stop();\n      setIsListening(false);\n    };\n  }, []);\n  const startListening = () => {\n    setText(\"\");\n    setIsListening(true);\n    recognition.start();\n  };\n  const stopListening = () => {\n    setIsListening(false);\n    recognition.stop();\n  };\n  return {\n    text,\n    isListening,\n    startListening,\n    stopListening,\n    hasRecognition: !!recognition\n  };\n};\n_s(useSpeechRecognition, \"YOMFEUt+oC72LKIeNX1WCieAo1w=\");\nexport default useSpeechRecognition;","map":{"version":3,"names":["React","useEffect","useState","recognition","window","SpeechRecognition","continuous","lang","useSpeechRecognition","_s","text","setText","isListening","setIsListening","onresult","event","console","log","stop","startListening","start","stopListening","hasRecognition"],"sources":["/Users/maryamcheema/Documents/VideoAccessibility/frontend/src/hooks/useSpeechRecognition.jsx"],"sourcesContent":["import React, { useEffect, useState } from \"react\";\n\nlet recognition: any = null;\nif (\"webkitSpeechRecongition\" in window) {\n  recognition = new window.SpeechRecognition();\n  recognition.continuous = true;\n  recognition.lang = \"en-US\";\n}\n\nconst useSpeechRecognition = () => {\n  const [text, setText] = useState(\"\");\n  const [isListening, setIsListening] = useState(false);\n\n  useEffect(() => {\n    if (!recognition) return;\n\n    recognition.onresult = (event) => {\n      console.log(\"on result event: \", event);\n      recognition.stop();\n      setIsListening(false);\n    };\n  }, []);\n\n  const startListening = () => {\n    setText(\"\");\n    setIsListening(true);\n    recognition.start();\n  }\n\n  const stopListening = () => {\n    setIsListening(false);\n    recognition.stop();\n  }\n\n  return {\n    text,\n    isListening,\n    startListening,\n    stopListening,\n    hasRecognition: !!recognition, \n  }\n};\n\nexport default useSpeechRecognition;\n"],"mappings":";AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,QAAQ,QAAQ,OAAO;AAElD,IAAIC,WAAgB,GAAG,IAAI;AAC3B,IAAI,yBAAyB,IAAIC,MAAM,EAAE;EACvCD,WAAW,GAAG,IAAIC,MAAM,CAACC,iBAAiB,CAAC,CAAC;EAC5CF,WAAW,CAACG,UAAU,GAAG,IAAI;EAC7BH,WAAW,CAACI,IAAI,GAAG,OAAO;AAC5B;AAEA,MAAMC,oBAAoB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACjC,MAAM,CAACC,IAAI,EAAEC,OAAO,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EACpC,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EAErDD,SAAS,CAAC,MAAM;IACd,IAAI,CAACE,WAAW,EAAE;IAElBA,WAAW,CAACW,QAAQ,GAAIC,KAAK,IAAK;MAChCC,OAAO,CAACC,GAAG,CAAC,mBAAmB,EAAEF,KAAK,CAAC;MACvCZ,WAAW,CAACe,IAAI,CAAC,CAAC;MAClBL,cAAc,CAAC,KAAK,CAAC;IACvB,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMM,cAAc,GAAGA,CAAA,KAAM;IAC3BR,OAAO,CAAC,EAAE,CAAC;IACXE,cAAc,CAAC,IAAI,CAAC;IACpBV,WAAW,CAACiB,KAAK,CAAC,CAAC;EACrB,CAAC;EAED,MAAMC,aAAa,GAAGA,CAAA,KAAM;IAC1BR,cAAc,CAAC,KAAK,CAAC;IACrBV,WAAW,CAACe,IAAI,CAAC,CAAC;EACpB,CAAC;EAED,OAAO;IACLR,IAAI;IACJE,WAAW;IACXO,cAAc;IACdE,aAAa;IACbC,cAAc,EAAE,CAAC,CAACnB;EACpB,CAAC;AACH,CAAC;AAACM,EAAA,CAhCID,oBAAoB;AAkC1B,eAAeA,oBAAoB"},"metadata":{},"sourceType":"module","externalDependencies":[]}